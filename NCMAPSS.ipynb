{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6128a6-a4a4-4c46-9c13-c962de6df75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "N-CMAPSS DS08a - RUL ì˜ˆì¸¡ ë° ê²½ë³´ ì‹œìŠ¤í…œ\n",
    "- Update: Piecewise RUL Max 30ìœ¼ë¡œ ì¡°ì • (ë‹¨ê¸° ì˜ˆì¸¡ ì§‘ì¤‘)\n",
    "- Update: Val RMSE > 8.0 ë°œìƒ ì‹œ ì¡°ê¸° ì¢…ë£Œ (Early Stopping) ë¡œì§ ì¶”ê°€\n",
    "- Base: Data Augmentation, Baseline Centering, Model Lightening ì ìš©ë¨\n",
    "\"\"\"\n",
    "\n",
    "# êµ¬ê¸€ ì½”ë© ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"âœ… Google Drive mounted!\")\n",
    "except:\n",
    "    print(\"âš ï¸ Not in Colab\")\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================\n",
    "# 0. ì„¤ì • (Configuration)\n",
    "# =============================\n",
    "H5_PATH = \"/content/drive/MyDrive/LIZaiMing/N-CMAPSS_DS08a-009.h5\"\n",
    "\n",
    "WINDOW_SIZE = 30\n",
    "STRIDE = 1\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# [ìˆ˜ì •] Piecewise RUL ì„¤ì • (50 -> 30)\n",
    "# ì´ì œ ëª¨ë¸ì€ 30 ì‚¬ì´í´ ì´í•˜(ê³ ì¥ ì„ë°•) êµ¬ê°„ë§Œ ì •ë°€í•˜ê²Œ ì˜ˆì¸¡í•˜ê³ ,\n",
    "# 30 ì´ìƒì€ ëª¨ë‘ 'ì•ˆì „(30)'ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.\n",
    "PIECEWISE_RUL_MAX = 30.0\n",
    "\n",
    "DANGER_THRESHOLD_RATIO = 0.10\n",
    "\n",
    "# ë…¸ì´ì¦ˆ ê°•ë„ ì„¤ì •\n",
    "NOISE_FACTOR = 0.05\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "def set_korean_font():\n",
    "    if 'google.colab' in str(get_ipython()):\n",
    "        if not os.path.exists('/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'):\n",
    "            os.system(\"sudo apt-get install -y fonts-nanum\")\n",
    "            os.system(\"sudo fc-cache -fv\")\n",
    "            os.system(\"rm ~/.cache/matplotlib -rf\")\n",
    "        font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "        plt.rc('font', family=fm.FontProperties(fname=font_path).get_name())\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "    else:\n",
    "        plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "set_korean_font()\n",
    "\n",
    "# =============================\n",
    "# 1. ë°ì´í„° ë¡œë“œ ë° RUL ë¼ë²¨ ìƒì„±\n",
    "# =============================\n",
    "def load_and_process_data():\n",
    "    print(\"[1] ë°ì´í„° ë¡œë”© ë° RUL ê³„ì‚° ì¤‘...\")\n",
    "    if not os.path.exists(H5_PATH):\n",
    "        raise FileNotFoundError(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {H5_PATH}\")\n",
    "\n",
    "    with h5py.File(H5_PATH, \"r\") as f:\n",
    "        W = f[\"W_dev\"][:].astype(np.float32)\n",
    "        Xs = f[\"X_s_dev\"][:].astype(np.float32)\n",
    "        X = np.concatenate([W, Xs], axis=1)\n",
    "\n",
    "        aux = f[\"A_dev\"][:]\n",
    "        unit_ids = aux[:, 0].astype(int)\n",
    "        cycles = aux[:, 1].astype(int)\n",
    "\n",
    "    print(f\"  X shape: {X.shape}\")\n",
    "\n",
    "    RUL = np.zeros(len(cycles))\n",
    "    max_life_dict = {}\n",
    "\n",
    "    for unit in tqdm(np.unique(unit_ids), desc=\"Generating RUL Labels\"):\n",
    "        mask = (unit_ids == unit)\n",
    "        unit_cycles = cycles[mask]\n",
    "        max_cycle = unit_cycles.max()\n",
    "        max_life_dict[unit] = max_cycle\n",
    "\n",
    "        linear_rul = max_cycle - unit_cycles\n",
    "        RUL[mask] = np.clip(linear_rul, 0, PIECEWISE_RUL_MAX)\n",
    "\n",
    "    print(f\"âœ… Piecewise RUL ìƒì„± ì™„ë£Œ (Max Limit: {PIECEWISE_RUL_MAX})\\n\")\n",
    "    return X, RUL, unit_ids, max_life_dict\n",
    "\n",
    "# =============================\n",
    "# 1-1. Baseline Centering\n",
    "# =============================\n",
    "def apply_baseline_centering(X, unit_ids, n_init_samples=50):\n",
    "    print(\"[Pre-processing] Baseline Centering ì ìš© ì¤‘...\")\n",
    "    X_centered = np.zeros_like(X)\n",
    "\n",
    "    for unit in tqdm(np.unique(unit_ids), desc=\"Centering\"):\n",
    "        mask = (unit_ids == unit)\n",
    "        X_unit = X[mask]\n",
    "\n",
    "        n_samples = min(len(X_unit), n_init_samples)\n",
    "        baseline = X_unit[:n_samples].mean(axis=0)\n",
    "        X_centered[mask] = X_unit - baseline\n",
    "\n",
    "    print(\"âœ… Baseline Centering ì™„ë£Œ\\n\")\n",
    "    return X_centered\n",
    "\n",
    "# =============================\n",
    "# 2. ìœˆë„ìš° ìƒì„±\n",
    "# =============================\n",
    "def create_windows(X, y, unit_ids, window_size, stride):\n",
    "    windows_X = []\n",
    "    windows_y = []\n",
    "    windows_unit = []\n",
    "\n",
    "    for unit in np.unique(unit_ids):\n",
    "        mask = (unit_ids == unit)\n",
    "        X_unit = X[mask]\n",
    "        y_unit = y[mask]\n",
    "\n",
    "        for i in range(0, len(X_unit) - window_size + 1, stride):\n",
    "            windows_X.append(X_unit[i : i + window_size])\n",
    "            windows_y.append(y_unit[i + window_size - 1])\n",
    "            windows_unit.append(unit)\n",
    "\n",
    "    return np.array(windows_X), np.array(windows_y), np.array(windows_unit)\n",
    "\n",
    "# =============================\n",
    "# 3. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (Noise Injection ì¶”ê°€)\n",
    "# =============================\n",
    "class RULDataset(Dataset):\n",
    "    def __init__(self, X, y, mode='train'):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y).unsqueeze(1)\n",
    "        self.mode = mode # 'train' or 'test'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_data = self.X[idx]\n",
    "        y_data = self.y[idx]\n",
    "\n",
    "        # í•™ìŠµ ëª¨ë“œì¼ ë•Œë§Œ ë…¸ì´ì¦ˆ ì¶”ê°€ (Data Augmentation)\n",
    "        if self.mode == 'train':\n",
    "            noise = torch.randn_like(x_data) * NOISE_FACTOR\n",
    "            x_data = x_data + noise\n",
    "\n",
    "        return x_data, y_data\n",
    "\n",
    "# =============================\n",
    "# 4. LSTM Regressor ëª¨ë¸ (ê²½ëŸ‰í™” ìœ ì§€)\n",
    "# =============================\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0.0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last_out = out[:, -1, :]\n",
    "        last_out = self.dropout(last_out)\n",
    "        pred = self.fc(last_out)\n",
    "        return pred\n",
    "\n",
    "# =============================\n",
    "# 5. í•™ìŠµ í•¨ìˆ˜ (Early Stopping ì¶”ê°€)\n",
    "# =============================\n",
    "def train_model(model, train_loader, val_loader):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.5)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    print(f\"\\n[ëª¨ë¸ í•™ìŠµ ì‹œì‘] Epochs: {EPOCHS} (Noise Factor: {NOISE_FACTOR})\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                preds = model(X_batch)\n",
    "                loss = criterion(preds, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        train_rmse = np.sqrt(train_loss)\n",
    "        val_rmse = np.sqrt(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train RMSE={train_rmse:.2f} | Val RMSE={val_rmse:.2f}\")\n",
    "\n",
    "        # [NEW] Early Stopping Check (RMSE > 8)\n",
    "        if val_rmse > 8.0:\n",
    "            print(f\"\\nğŸš¨ [Early Stopping] Val RMSE({val_rmse:.2f})ê°€ ì„ê³„ê°’(8.0)ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            print(\"   ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ í•™ìŠµì„ ì¡°ê¸° ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_rul_model.pt')\n",
    "            print(\"  âœ“ Best Model Saved\")\n",
    "\n",
    "    print(\"âœ… í•™ìŠµ ì¢…ë£Œ. (ì €ì¥ëœ Best Modelë¡œ í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤)\")\n",
    "\n",
    "# =============================\n",
    "# 6. í‰ê°€ ë° ì‹œê°í™”\n",
    "# =============================\n",
    "def evaluate_and_plot(model, X_test, y_test, unit_test, max_life_dict):\n",
    "    model.eval()\n",
    "\n",
    "    # Test ì‹œì—ëŠ” ë…¸ì´ì¦ˆ ì—†ì´ í‰ê°€ (mode='test')\n",
    "    test_ds = RULDataset(X_test, y_test, mode='test')\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            preds = model(X_batch)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds).flatten()\n",
    "\n",
    "    mse = mean_squared_error(y_test, all_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, all_preds)\n",
    "    r2 = r2_score(y_test, all_preds)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\" [ìµœì¢… ëª¨ë¸ ì„±ëŠ¥ í‰ê°€] \")\n",
    "    print(f\" RMSE (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨): {rmse:.4f}\")\n",
    "    print(f\" MAE  (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨)  : {mae:.4f}\")\n",
    "    print(f\" R2 Score (ê²°ì • ê³„ìˆ˜)   : {r2:.4f}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    unique_test_units = np.unique(unit_test)\n",
    "\n",
    "    for unit in unique_test_units:\n",
    "        mask = (unit_test == unit)\n",
    "        y_true_unit = y_test[mask]\n",
    "        y_pred_unit = all_preds[mask]\n",
    "\n",
    "        max_life = max_life_dict[unit]\n",
    "        danger_rul = max_life * DANGER_THRESHOLD_RATIO\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.plot(y_true_unit, label='Actual RUL (ì •ë‹µ)', color='black', linestyle='--')\n",
    "        plt.plot(y_pred_unit, label='Predicted RUL (ì˜ˆì¸¡)', color='blue')\n",
    "\n",
    "        plt.axhline(y=PIECEWISE_RUL_MAX, color='green', linestyle=':', label=f'Max RUL Limit ({int(PIECEWISE_RUL_MAX)})')\n",
    "        plt.axhline(y=danger_rul, color='red', linestyle='-', linewidth=2, label=f'Danger Threshold ({int(danger_rul)} cycles)')\n",
    "        plt.fill_between(range(len(y_true_unit)), 0, danger_rul, color='red', alpha=0.1)\n",
    "\n",
    "        alarm_idx = np.where(y_pred_unit < danger_rul)[0]\n",
    "        if len(alarm_idx) > 0:\n",
    "            first_alarm = alarm_idx[0]\n",
    "            plt.scatter(first_alarm, y_pred_unit[first_alarm], color='red', s=100, zorder=5, marker='*', label='ğŸš¨ Alarm Triggered')\n",
    "            print(f\"\\n[Unit {unit}] ğŸš¨ ê²½ë³´ ë°œë ¹! ì˜ˆì¸¡ RULì´ {danger_rul:.1f} ë¯¸ë§Œìœ¼ë¡œ ë–¨ì–´ì¡ŒìŠµë‹ˆë‹¤. (Time: {first_alarm})\")\n",
    "\n",
    "        plt.title(f'Piecewise RUL Prediction - Unit {unit} (Max Life: {max_life})')\n",
    "        plt.xlabel('Time (Window Step)')\n",
    "        plt.ylabel('Remaining Useful Life (Cycle)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "# =============================\n",
    "# 7. ë©”ì¸ ì‹¤í–‰\n",
    "# =============================\n",
    "def main():\n",
    "    X, RUL, unit_ids, max_life_dict = load_and_process_data()\n",
    "\n",
    "    X = apply_baseline_centering(X, unit_ids, n_init_samples=50)\n",
    "\n",
    "    unique_units = np.unique(unit_ids)\n",
    "    test_units = unique_units[-2:]\n",
    "    train_units = unique_units[:-2]\n",
    "\n",
    "    print(f\"Train Units: {train_units}\")\n",
    "    print(f\"Test Units: {test_units}\")\n",
    "\n",
    "    train_mask = np.isin(unit_ids, train_units)\n",
    "    test_mask = np.isin(unit_ids, test_units)\n",
    "\n",
    "    X_train_raw, RUL_train_raw = X[train_mask], RUL[train_mask]\n",
    "    X_test_raw, RUL_test_raw = X[test_mask], RUL[test_mask]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_raw)\n",
    "    X_test_scaled = scaler.transform(X_test_raw)\n",
    "\n",
    "    print(\"\\n[3] ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìƒì„± ì¤‘...\")\n",
    "    X_train_win, y_train_win, _ = create_windows(X_train_scaled, RUL_train_raw, unit_ids[train_mask], WINDOW_SIZE, STRIDE)\n",
    "    X_test_win, y_test_win, u_test_win = create_windows(X_test_scaled, RUL_test_raw, unit_ids[test_mask], WINDOW_SIZE, STRIDE)\n",
    "\n",
    "    print(f\"  Train Windows: {X_train_win.shape}\")\n",
    "    print(f\"  Test Windows:  {X_test_win.shape}\")\n",
    "\n",
    "    # Train Loader ìƒì„± ì‹œ mode='train'ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì£¼ì…\n",
    "    train_ds = RULDataset(X_train_win, y_train_win, mode='train')\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "    # Val Loader ìƒì„± ì‹œ mode='test'ë¡œ ë…¸ì´ì¦ˆ ì œê±° (ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´)\n",
    "    val_ds = RULDataset(X_test_win, y_test_win, mode='test')\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = LSTMRegressor(input_dim=X.shape[1]).to(device)\n",
    "    train_model(model, train_loader, val_loader)\n",
    "\n",
    "    # ì¡°ê¸° ì¢…ë£Œ ë˜ë”ë¼ë„ ì €ì¥ëœ ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¡œë“œ ì‹œë„\n",
    "    if os.path.exists('best_rul_model.pt'):\n",
    "        model.load_state_dict(torch.load('best_rul_model.pt'))\n",
    "        print(\"\\nğŸ”„ Best Model ë¡œë“œ ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ ì €ì¥ëœ Best Modelì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ëª¨ë¸ë¡œ í‰ê°€í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    evaluate_and_plot(model, X_test_win, y_test_win, u_test_win, max_life_dict)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9d572-89b5-445d-af39-8edcc0ef7cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mp_env)",
   "language": "python",
   "name": "mp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
